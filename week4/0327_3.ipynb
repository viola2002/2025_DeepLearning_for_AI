{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viola2002/2025_DeepLearning_for_AI/blob/main/0327_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "896EjBJYTefi"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.ones(size=(2, 1)) #1 Unlike in other frameworks, the shape argument is named ''size'' rather than ''shape''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIhSM4IlTqzf",
        "outputId": "8780decb-3ff5-4b60-c4e2-bc8efa4041a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(size=(2, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX4WlJkVTrgf",
        "outputId": "8c3ea9db-ca1b-4503-c74d-3ed73089a455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1, 2, 3], dtype=torch.float32) #2 Unlike in other frameworks, you cannot pass dtype=''float32'' as a string. The dtype argument must be a torch dtype instance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSfUwxNgTf1M",
        "outputId": "d6c3511c-abf9-4025-cd5d-7040d37af0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.normal( #1 Equivalent to tf.random.normal(shape=(3, 1), mean=0., stddev=1.)\n",
        "... mean=torch.zeros(size=(3, 1)),\n",
        "... std=torch.ones(size=(3, 1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0b_3RQ8TtO6",
        "outputId": "187c724f-1939-4156-9cff-8ef4dcdce853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1964],\n",
              "        [-0.5197],\n",
              "        [-0.1983]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3, 1) #1 Equivalent to tf.random.uniform(shape=(3, 1), minval=0., maxval=1.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhzycIlmT8eI",
        "outputId": "d1c3cbd2-2a11-4372-c499-e9d29c9f9291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8916],\n",
              "        [0.5327],\n",
              "        [0.2667]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEVW1eJyUStt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Like NumPy arrays, but unlike TensorFlow tensors, PyTorch tensors are assignable."
      ],
      "metadata": {
        "id": "rCsdLfzsUTva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(size=(2, 1))"
      ],
      "metadata": {
        "id": "9fCcq_XHUEtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0, 0] = 1.\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATmpJn6uUG_J",
        "outputId": "389e08c5-5159-4937-aaf2-cb2475d51cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While you can just use a regular torch.Tensor to store the trainable state of a model,\n",
        "PyTorch does provide a specialized tensor subclass for that purpose, the\n",
        "torch.nn.parameter.Parameter class. Compared to a regular tensor, it provides semantic\n",
        "clarity – if you see a Parameter, you’ll know it’s a piece of trainable state, whereas a\n",
        "Tensor could be anything. As a result, it enables PyTorch to automatically track and\n",
        "retrieve the Parameters you assign to PyTorch models – similar to what Keras does with\n",
        "Keras Variable instances."
      ],
      "metadata": {
        "id": "OuhH_0mYUhJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(size=(2, 1))\n",
        "p = torch.nn.parameter.Parameter(data=x) #1 A Parameter can only be created using a torch.Tensor value – no NumPy arrays allowed."
      ],
      "metadata": {
        "id": "WHHswix0UIT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((2, 2))\n",
        "b = torch.square(a) #1 Take the square, same as np.square\n",
        "c = torch.sqrt(a) #2 Take the square root, same as np.sqrt\n",
        "d = b + c #3 Add two tensors (element-wise)\n",
        "e = torch.matmul(a, b) #4 Take the product of two tensors (see chapter 2), same as np.matmul\n",
        "f = torch.cat((a, b), axis=0) #5 Concatenate a and b along axis 0, same as np.concatenate"
      ],
      "metadata": {
        "id": "_Cp6bdOJUlCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense layer"
      ],
      "metadata": {
        "id": "FzfKXRlPUzvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense(inputs, W, b):\n",
        "  return torch.nn.relu(torch.matmul(inputs, W) + b)\n"
      ],
      "metadata": {
        "id": "dgIOTUtpUv4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HoLF3oBKVFCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COMPUTING GRADIENTS WITH PYTORCH"
      ],
      "metadata": {
        "id": "BjDaEfSaVFlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_var = torch.tensor(3.0, requires_grad=True) #1 In order to compute gradients with respect to a tensor, it must be created with requires_grad=True.\n",
        "result = torch.square(input_var) #2 Calling backward() populates the ''grad'' attribute on all tensors create with requires_grad=True.\n",
        "result.backward()\n",
        "gradient = input_var.grad\n",
        "gradient\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAxAl2zLUwL9",
        "outputId": "dc167efc-b2ae-409f-e1c2-00310576f532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you call backward() multiple times in a row, the .grad attribute will ''accumulate''\n",
        "gradients: each new call will sum the new gradient with the preexisting one. For instance,\n",
        "in the code below, input_var.grad is not the gradient of square(input_var) with respect\n",
        "to input_var, rather it is the sum of that gradient and the previously computed gradient –\n",
        "hence its value has doubled since our last code snippet."
      ],
      "metadata": {
        "id": "cPaSQ9HbVO3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = torch.square(input_var)\n",
        "result.backward()\n",
        "input_var.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3m-kYb-U6ua",
        "outputId": "6a31c56c-d31e-48ab-a59f-8281ed6faf08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12.)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to reset gradients, you can just set .grad to None:"
      ],
      "metadata": {
        "id": "A81Iq5UaVefL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_var.grad = None"
      ],
      "metadata": {
        "id": "6AVMG4vfVLMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = torch.square(input_var) #2 Calling backward() populates the ''grad'' attribute on all tensors create with requires_grad=True.\n",
        "result.backward()\n",
        "gradient = input_var.grad\n",
        "gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLHSihInVgM3",
        "outputId": "2887821a-b9b2-4e62-e199-4ac1e7325dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An end-to-end example: a linear classifier in pure PyTorch"
      ],
      "metadata": {
        "id": "ipbl6lEwVs8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "requires_grad=True"
      ],
      "metadata": {
        "id": "Ip9IlLz9WiwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "W = torch.rand(input_dim, output_dim, requires_grad=True)\n",
        "b = torch.zeros(output_dim, requires_grad=True)"
      ],
      "metadata": {
        "id": "BOndVLhnViAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our model"
      ],
      "metadata": {
        "id": "v1_17wjjWfC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(inputs, W, b):\n",
        "  return torch.matmul(inputs, W) + b"
      ],
      "metadata": {
        "id": "Pjz9sOjEVxLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just switch from tf.square to torch.square and from\n",
        "tf.reduce_mean to tf.mean."
      ],
      "metadata": {
        "id": "dLK3Q_-kWnhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(targets, predictions):\n",
        "  per_sample_losses = torch.square(targets - predictions)\n",
        "  return torch.mean(per_sample_losses)"
      ],
      "metadata": {
        "id": "zVOanUJwWZSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "def training_step(inputs, targets, W, b):\n",
        "  predictions = model(inputs) #1 Forward pass\n",
        "  loss = mean_squared_error(targets, predictions) #1\n",
        "  loss.backward() #2 Compute gradients\n",
        "  grad_loss_wrt_W, grad_loss_wrt_b = W.grad, b.grad #3 Retrieve gradients\n",
        "  with torch.no_grad():\n",
        "    W -= grad_loss_wrt_W * learning_rate #4 Update weights inside a no_grad scope\n",
        "    b -= grad_loss_wrt_b * learning_rate #4\n",
        "  W.grad = None #5 Reset gradients\n",
        "  b.grad = None #5\n",
        "return loss"
      ],
      "metadata": {
        "id": "cZIg4IKPWcTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the training step. Here’s how it works:\n",
        "1. loss.backward() runs backpropagation starting from the loss output\n",
        "node, and populates the tensor.grad attribute on all tensors that were\n",
        "involved in the computation of loss. tensor.grad represents the\n",
        "gradient of the loss with regard to that tensor.\n",
        "2. We use the .grad attribute to recover the gradients of the loss with\n",
        "regard to W and b.\n",
        "3. We update W and b using those gradients. Because these updates are not\n",
        "intended to be part of the backwards pass, we do them inside a\n",
        "torch.no_grad() scope, which skips gradient computation for everything\n",
        "inside it.\n",
        "4. We reset the contents of the .grad property of our W and b parameters,\n",
        "by setting it None. If we didn’t do this, gradient values would accumulate\n",
        "across multiple calls to training_step(), resulting in invalid values."
      ],
      "metadata": {
        "id": "6-tVOT58XAbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PACKAGING STATE AND COMPUTATION WITH MODULES"
      ],
      "metadata": {
        "id": "uzZ5osZaXJN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch also has a higher-level, object-oriented API for performing backpropagation, which\n",
        "requires relying on two new classes: the torch.nn.Module class, as well as an optimizer\n",
        "class from the torch.optim module, such as torch.optim.SGD (the equivalent of\n",
        "keras.optimizers.SGD).\n",
        "The general idea is to define a subclass of torch.nn.Module, which will:\n",
        "1. Hold some Parameters, to store state variables. Those are defined in the\n",
        "init() method.\n",
        "2. Implement the forward pass computation in the forward() method."
      ],
      "metadata": {
        "id": "BlrJfi7LXM0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.W = torch.nn.Parameter(torch.rand(input_dim, output_dim))\n",
        "    self.b = torch.nn.Parameter(torch.zeros(output_dim))\n",
        "  def forward(self, inputs):\n",
        "    return torch.matmul(inputs, self.W) + self.b\n"
      ],
      "metadata": {
        "id": "I-k76t53XA9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearModel()"
      ],
      "metadata": {
        "id": "jfIsXETvXUWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using an instance of torch.nn.Module, rather than calling the forward() method\n",
        "directly, you’d use call(), which redirects to forward() but adds a few framework hooks\n",
        "to it."
      ],
      "metadata": {
        "id": "G4bXFAaWYEgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[1., 2.], [3., 4.]])\n",
        "torch_inputs = torch.tensor(inputs)\n",
        "output = model(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5o_OoQFXZGb",
        "outputId": "0b2786a3-8150-47a6-ea5f-28e69e683146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-55ecfda2ae0f>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch_inputs = torch.tensor(inputs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoSAE_TdXeqK",
        "outputId": "d484f930-ae1c-4a09-ff3c-f5d0cd457fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3697],\n",
              "        [0.8545]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s get our hands on a PyTorch optimizer. To instantiate it, you will need to provide\n",
        "the list of parameters that the optimizer is intended to update. You can retrieve it from our\n",
        "Module instance via .parameters()."
      ],
      "metadata": {
        "id": "Qcyr4MOQX-Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters()) #, lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "4xkIf18OXqzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using our Module instance and the PyTorch SGD optimizer, can run a simplified training step:"
      ],
      "metadata": {
        "id": "EZHaKEEJYAml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(inputs, targets):\n",
        "  predictions = model(inputs)\n",
        "  loss = mean_squared_error(targets, predictions)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  model.zero_grad()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "saBGfkDWXt_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAKING PYTORCH MODULES FAST USING COMPILATION\n"
      ],
      "metadata": {
        "id": "9vswCO7pYNIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One last thing. Similarly to how TensorFlow lets you compile functions for better\n",
        "performance, PyTorch lets you compile functions or even Module instances, via the\n",
        "torch.compile() utility. This API leverages PyTorch’s very own compiler, named Dynamo.\n",
        "Let’s try it on our linear regression Module:"
      ],
      "metadata": {
        "id": "QtxBmSJtYZKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_model = model.compile()"
      ],
      "metadata": {
        "id": "2v-xBn-fX5NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting object is intended to work identically to the original – except the forward and\n",
        "backward pass should run faster.\n",
        "You can also leverage torch.compile() as a function decorator:"
      ],
      "metadata": {
        "id": "Adk6h0mxYWTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.compile\n",
        "def dense(inputs, W, b):\n",
        "  return torch.nn.relu(torch.matmul(inputs, W) + b)"
      ],
      "metadata": {
        "id": "GSiX8djUYQNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GABeBPDTYUVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}