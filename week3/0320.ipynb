{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viola2002/2025_DeepLearning_for_AI/blob/main/0320.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifefUr-3bUqY"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxKSzMZ1bUqk"
      },
      "source": [
        "# The mathematical building blocks of neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRS_VN5jbUqm"
      },
      "source": [
        "## A first look at a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVEqiRmbbUqn"
      },
      "source": [
        "**Loading the MNIST dataset in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8PmHFo69bUqo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() # train과 test로 분리"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ?를 덧붙여 도움말 실행\n",
        "mnist.load_data?"
      ],
      "metadata": {
        "id": "IZu79PzsK-j5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8OvFec-ubUqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8dbfc44-733a-4e14-b937-842210a850c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# train 이미지 데이터 차원 출력\n",
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uFTFgKdgbUqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773d6bdd-4ebc-4795-e2c2-cf9224ebdede"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# train 이미지 데이터 label 개수\n",
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fb8B1u1ZbUqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d543b39f-0678-4fc0-f99c-83d6403af94f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eac895rrbUqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03609695-ff03-478e-e79f-aa43d5c437fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# test 이미지 데이터 차원 출력\n",
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 이미지의 벡터\n",
        "train_images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ce9aXM6YMFiH",
        "outputId": "2e6bd99c-f8fa-4461-ca89-de664e5a5d55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-b0627a74-a360-427b-a999-4043fb49bcb9\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-b0627a74-a360-427b-a999-4043fb49bcb9 button').onclick = (e) => {\n",
              "        document.querySelector('#id-b0627a74-a360-427b-a999-4043fb49bcb9').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-b0627a74-a360-427b-a999-4043fb49bcb9 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 이미지의 벡터\n",
        "# show data 클릭 -> 28*28 pixel data\n",
        "train_images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "O5X6yW9nL1Hg",
        "outputId": "c1bef088-9fc2-46e8-877e-a69ecf92cdb3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-c2f7b260-1444-498e-b8ff-6dae62ffa511\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-c2f7b260-1444-498e-b8ff-6dae62ffa511 button').onclick = (e) => {\n",
              "        document.querySelector('#id-c2f7b260-1444-498e-b8ff-6dae62ffa511').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-c2f7b260-1444-498e-b8ff-6dae62ffa511 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p2SDmC-xbUq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bfab33-4655-4f4e-e048-c8588c7b01e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# test 이미지 데이터 label 개수\n",
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oVdqtSEObUq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9477bc36-4684-4180-d91a-34d8c46430b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTDGvYvIbUq3"
      },
      "source": [
        "**The network architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NkkcVjfHbUq4"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"), # 1st dense layer\n",
        "    layers.Dense(10, activation=\"softmax\") # 2nd dense layer # 0~9\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `keras.Sequential()`\n",
        "  - [TensorFlow/Model/with_the_sequential_class](https://www.tensorflow.org/api_docs/python/tf/keras/Model#with_the_sequential_class)\n",
        "- `layers`\n",
        "  - `Dense()`(fully connected), `Conv2D()`(onvolutional), `LSTM()`, etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "B1eLXJTJorPj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFIA6WcGbUq5"
      },
      "source": [
        "**The compilation step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vQxqgI_VbUq6"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\", # 최적화 기법 # rmsprop: RMS(Root Mean Square) 이용\n",
        "              loss=\"sparse_categorical_crossentropy\", # 손실 함수 # sparse_categorical_crossentropy: 희소 범주형 교차 엔트로피\n",
        "              metrics=[\"accuracy\"]) # 모델의 평가 지표"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `model.compile()`\n",
        "  - [TensorFlow/Model/compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)\n",
        "- `optimizer`\n",
        "  - \"rmsprop\", \"SGD\"(Stochastic Gradient Descent), etc.\n",
        "  - [TensorFlow/optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
        "- `loss` (function)\n",
        "  - \"sparse_categorical_crossentropy\", etc.\n",
        "  - [TensorFlow/losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
        "- `metrics`\n",
        "  - [TenserFlow/metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)"
      ],
      "metadata": {
        "id": "JGs5sdw8OM3v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmuZ14xbUq7"
      },
      "source": [
        "**Preparing the image data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c5jMlmvWbUq7"
      },
      "outputs": [],
      "source": [
        "# each pixel's value ranges from 0 to 255 (i.e., 256 possible values)\n",
        "# so we divide by 255 to normalize the pixel values to the range [0, 1]\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWzl4WxabUq9"
      },
      "source": [
        "**\"Fitting\" the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jJTLPuM_bUq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ee2e1e-8ba8-4f44-e842-316b5852fbf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.4389\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.1160\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0732\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0515\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f5b51d380d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [TensorFlow/Model/fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
        "  - epochs\n",
        "    - Number of epochs to train the model\n",
        "    - An epoch is an iteration over the entire x and y data provided\n",
        "    - = 모델이 훈련 데이터셋을 반복해서 학습할 횟수\n",
        "  - batch_size\n",
        "    - Number of samples per gradient update\n",
        "    - = 모델이 한 번의 학습에서 처리할 훈련 데이터의 샘플 수"
      ],
      "metadata": {
        "id": "lizPmKLQTdRp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0QrFhUFbUq9"
      },
      "source": [
        "**Using the model to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kIGZfFdbbUq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebca8d1-9682-4405-a096-545ea333ca48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.1966116e-07, 8.9264640e-09, 6.7470737e-06, 5.1698793e-05,\n",
              "       1.0198747e-10, 1.9905690e-07, 2.4464389e-11, 9.9993992e-01,\n",
              "       2.6101733e-07, 9.7478198e-07], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JDUElVj3bUq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080b265f-12ba-4a2f-dc33-6b49e6839951"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(7)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "predictions[0].argmax() # argmax(): 가장 큰 값의 인덱스를 반환하는 함수 -> 가장 높은 확률을 가진 클래스의 인덱스 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fc7C5zxUbUrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8765ab-ff66-4f3d-e4b8-ebcf42b96e13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.9999399)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "predictions[0][7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-NB6Y0PgbUrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02112b87-4c67-4f16-a64d-08640884ccb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(7)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ `predictions`와 `test_labels`를 비교해보니 일치함"
      ],
      "metadata": {
        "id": "qwlsff9WQygp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 비교\n",
        "print(len(model.weights))\n",
        "print()\n",
        "print(model.weights[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqTCEDhjRKHz",
        "outputId": "3fcf2cfc-43d6-493e-abaa-f0048b9765ee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "\n",
            "<Variable path=sequential/dense/kernel, shape=(784, 512), dtype=float32, value=[[-0.0388724   0.03989542  0.02199894 ...  0.03977191  0.00432776\n",
            "   0.02924845]\n",
            " [ 0.05256087  0.0152437  -0.05661645 ...  0.03649601  0.05718294\n",
            "   0.01645888]\n",
            " [ 0.02476799 -0.06164347  0.01105776 ...  0.06395976  0.02474947\n",
            "  -0.03618941]\n",
            " ...\n",
            " [ 0.00473872  0.00412759  0.0474704  ... -0.0643976   0.01076498\n",
            "   0.05786359]\n",
            " [-0.02373781 -0.0231631   0.05848829 ...  0.02720951 -0.04483289\n",
            "  -0.02325505]\n",
            " [ 0.05419935 -0.04996667 -0.0479296  ... -0.0313643   0.00050589\n",
            "   0.01524273]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGpS4SuXbUrB"
      },
      "source": [
        "**Evaluating the model on new data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N32z_aAxbUrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c96b84-e761-42b2-aa48-88d2ac74bbc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0854\n",
            "test_acc: 0.977400004863739\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bTEPblbUrC"
      },
      "source": [
        "## Data representations for neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-4jaTM3bUrC"
      },
      "source": [
        "### Scalars (rank-0 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uSVGtfA5bUrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c34e54-edd4-4753-9588-6870ac0619fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(12)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2SoUL9IzbUrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b7f913-912a-40a4-b7b9-65bdde5dc541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9QJWHXUbUrE"
      },
      "source": [
        "### Vectors (rank-1 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kh7qEvvvbUrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93141546-d7d9-4977-f584-2549269f8166"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12,  3,  6, 14,  7])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "x = np.array([12, 3, 6, 14, 7])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IOBMsif5bUrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f241b4d-5ff1-4366-af4a-97da5ecf88b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuhhWhVNbUrG"
      },
      "source": [
        "### Matrices (rank-2 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QLcVWStvbUrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be29eb7d-c820-4cec-d3e0-b17ca5826868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa1Gd8TObUrI"
      },
      "source": [
        "### Rank-3 and higher-rank tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Al7TuKJnbUrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7590fb3-2250-4150-d0e7-16a26e2c8cb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibDEDReGbUrJ"
      },
      "source": [
        "### Key attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "e7vBbujGbUrK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "x6uuZ8wCbUrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689fd498-c5b5-4259-8e78-5fc2a7a33797"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "train_images.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MQOEDRtCbUrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63729d4d-272b-4f93-c53b-d4eb4b029ff6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "C6d47h9NbUrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475fd6c8-639b-4e1f-cb99-b614023748c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "train_images.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgQCdwGsbUrY"
      },
      "source": [
        "**Displaying the fourth digit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YvYgbSU5bUrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "2a2c1431-604c-489f-9c8f-5829e3ac632e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[7]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "fWCulKQdYGLH",
        "outputId": "7a0d6b7c-0190-435d-dc6b-71d752fb4d82"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "colab의 AI 코드 생성을 이용하면 편리함. 단, 시험에서는 금지됨."
      ],
      "metadata": {
        "id": "6MI12BS7Xu5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Wqn1F-SabUrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f516743-28ef-43f7-ef44-2ecb9b216149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(9)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "train_labels[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8Nb8-fAbUra"
      },
      "source": [
        "### Manipulating tensors in NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8EKJK98mbUra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bc9c86-ad4c-4c4d-b12a-f83406d3368f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "my_slice = train_images[10:100]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iUMpKfUGbUrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f932f13-78f9-48ac-ed1d-0b05a602e592"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "my_slice = train_images[10:100, :, :]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YP2LObB2bUrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57f41c2-4630-49df-cdce-1ad7a4408e05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ndmt9ttPbUrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c490e18-6048-4a47-a282-cad3b4bd9af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 14, 14)\n"
          ]
        }
      ],
      "source": [
        "my_slice = train_images[:, 14:, 14:]\n",
        "\n",
        "print(my_slice.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ACx2wTu3bUrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a49554-878e-4a14-f7ed-818f3aa3875c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 14, 14)\n"
          ]
        }
      ],
      "source": [
        "my_slice = train_images[:, 7:-7, 7:-7]\n",
        "\n",
        "print(my_slice.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMQst_lsbUrd"
      },
      "source": [
        "### The notion of data batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NqfhxINEbUrf"
      },
      "outputs": [],
      "source": [
        "batch = train_images[:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QO_LVC0jbUrg"
      },
      "outputs": [],
      "source": [
        "batch = train_images[128:256]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "i4SJVnR5bUrg"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "batch = train_images[128 * n:128 * (n + 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmyO8MUObUrg"
      },
      "source": [
        "### Real-world examples of data tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj-Ph0HDbUri"
      },
      "source": [
        "### Vector data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMfa7ZiYbUri"
      },
      "source": [
        "### Timeseries data or sequence data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILE2DBDPbUrj"
      },
      "source": [
        "### Image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTnFxj3bbUrk"
      },
      "source": [
        "### Video data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBMrEQ4bUrl"
      },
      "source": [
        "## The gears of neural networks: tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔼**2025.03.13**\n"
      ],
      "metadata": {
        "id": "acOFIejWPaYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔽**2025.03.20**"
      ],
      "metadata": {
        "id": "4cChAr0PQCwQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hl8sJrvbUrl"
      },
      "source": [
        "### Element-wise operations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚓\n",
        "<br> Why do we need to use `copy()`?\n",
        "<br> If we do not use `copy()`, then the original one is changed.\n",
        "<br> So we should use copy of original one."
      ],
      "metadata": {
        "id": "GX-VstuLS2Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`assert` in python\n",
        "  - [wikidocs/assert](https://wikidocs.net/21050)"
      ],
      "metadata": {
        "id": "uud_3p6pVMDF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fo4wwgbFbUrm"
      },
      "outputs": [],
      "source": [
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "OjOahqVBbUrm"
      },
      "outputs": [],
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "XVfgrm53bUrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550383c3-c58d-4bd8-dc31-7324ac576895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took: 0.01 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "L5ymhwHBbUro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e450303-ecf5-4145-a024-d0ea9d94ef04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took: 1.60 s\n"
          ]
        }
      ],
      "source": [
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅Naive methods are slower because it operates element-wisely. We should use vectorized ones."
      ],
      "metadata": {
        "id": "RCmI7PXoQkyr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bujGT-8TbUro"
      },
      "source": [
        "### Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "MJvjdWVDbUrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220a2134-83e4-4333-bf28-a8e230744404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.17937016e-01 5.39253522e-02 3.27035518e-01 6.99956688e-01\n",
            "  9.05821985e-01 5.85876263e-01 5.19046454e-01 8.00034739e-02\n",
            "  7.15357254e-01 6.40614067e-01]\n",
            " [5.56989306e-02 6.07655003e-01 4.93885548e-01 9.68074310e-01\n",
            "  8.57821207e-01 5.82307205e-01 8.43030432e-01 2.09637223e-01\n",
            "  1.54704408e-02 4.09780458e-01]\n",
            " [3.16907960e-01 9.59494164e-01 3.00214979e-01 3.65475789e-01\n",
            "  5.98368672e-01 6.64041450e-02 6.84323372e-01 5.33171978e-01\n",
            "  5.11334480e-01 9.96577145e-01]\n",
            " [9.67928167e-01 8.98471133e-01 7.55619797e-01 4.78268437e-01\n",
            "  5.90118619e-02 5.46582579e-01 5.50616194e-01 2.89626544e-01\n",
            "  3.75507515e-02 4.43274886e-01]\n",
            " [6.97683789e-01 7.43149604e-01 1.38893750e-01 1.57368730e-01\n",
            "  5.50242956e-01 9.29076090e-01 2.22652106e-01 2.39209257e-01\n",
            "  9.89798919e-01 2.05498413e-01]\n",
            " [3.65155060e-01 6.31524531e-01 1.74978099e-01 4.78944661e-01\n",
            "  7.85103558e-01 5.06731099e-01 7.70345736e-01 3.69404402e-01\n",
            "  3.51519367e-02 4.12675230e-01]\n",
            " [1.57811057e-01 6.33832608e-01 7.05936254e-01 5.31271970e-01\n",
            "  4.89590503e-02 9.80650702e-01 8.68665702e-01 7.67410033e-01\n",
            "  7.50573463e-01 7.24380512e-01]\n",
            " [5.96645646e-01 7.54983087e-01 9.74696384e-01 6.62560587e-01\n",
            "  3.50812789e-01 2.70735467e-01 8.02305671e-02 2.16901505e-01\n",
            "  5.70546499e-01 8.25967497e-01]\n",
            " [8.15478501e-01 1.02189155e-01 1.00425897e-01 9.07549341e-01\n",
            "  4.30552242e-01 1.94872495e-01 3.72197625e-01 3.87256175e-01\n",
            "  8.24654200e-01 2.68510603e-01]\n",
            " [7.96604005e-01 8.51971929e-01 2.56452880e-01 7.20135729e-01\n",
            "  2.21213320e-01 8.79169509e-01 5.01406808e-01 1.94809341e-01\n",
            "  9.50529814e-02 1.36382030e-01]\n",
            " [6.38879702e-01 1.57109124e-01 6.58368128e-01 5.77648020e-01\n",
            "  2.47604984e-01 5.76425139e-01 2.00287617e-01 2.91433353e-02\n",
            "  1.38061307e-01 3.46989035e-02]\n",
            " [1.75724909e-01 6.77791022e-01 8.28769414e-01 4.34126077e-01\n",
            "  6.70351192e-01 2.13684189e-01 3.75754647e-01 7.40602635e-01\n",
            "  1.25623638e-01 8.91361440e-01]\n",
            " [8.80762724e-01 7.60152436e-01 3.09990899e-01 2.72205371e-01\n",
            "  4.85335743e-01 2.92691397e-01 3.18084818e-01 2.46570566e-01\n",
            "  2.92156190e-01 7.26784700e-01]\n",
            " [5.60697947e-01 4.56050795e-01 8.84616788e-01 1.28521111e-01\n",
            "  5.95987634e-01 5.99975933e-02 9.61537623e-01 9.87239933e-01\n",
            "  5.14140686e-02 3.11081309e-01]\n",
            " [9.80753984e-01 6.08825923e-01 9.33475835e-01 8.87407239e-01\n",
            "  5.21946283e-01 3.22760417e-01 8.59490574e-01 9.61768243e-01\n",
            "  4.65258391e-02 6.37589577e-01]\n",
            " [2.76947157e-01 5.82024940e-01 4.64324958e-02 5.58118593e-01\n",
            "  4.70079927e-01 9.30809905e-01 2.35767310e-03 2.57822572e-01\n",
            "  5.06282980e-01 8.27443208e-01]\n",
            " [4.72160935e-01 7.90276919e-01 2.22923538e-01 4.98248073e-01\n",
            "  3.43256839e-01 7.41852588e-01 2.29561360e-01 4.00648587e-01\n",
            "  3.76630325e-02 3.53738736e-01]\n",
            " [6.63694282e-01 5.10414393e-01 5.41698554e-02 5.18597324e-01\n",
            "  1.51965422e-01 8.68520404e-02 3.66471599e-01 8.97919888e-01\n",
            "  8.04262567e-01 5.88042008e-01]\n",
            " [7.92596242e-02 2.17531939e-01 2.94136808e-01 1.33139927e-01\n",
            "  2.71348921e-01 7.48702820e-01 9.35257334e-03 5.34162899e-01\n",
            "  7.61901322e-01 6.31064937e-01]\n",
            " [5.64955063e-01 5.72863890e-01 3.32083595e-01 9.15529946e-01\n",
            "  8.18886282e-01 8.80586270e-01 4.01962161e-01 5.73846393e-01\n",
            "  3.52360566e-01 8.82251318e-01]\n",
            " [1.14741938e-01 6.17139979e-01 7.79131696e-03 6.28389083e-01\n",
            "  6.74538806e-01 1.68853092e-01 3.97228556e-01 6.65342454e-01\n",
            "  5.04108126e-01 7.71489772e-01]\n",
            " [6.70736724e-01 4.31028402e-01 5.70605000e-01 6.11936335e-01\n",
            "  4.33921164e-01 1.95566931e-03 5.01746425e-01 7.92804582e-03\n",
            "  6.78376118e-01 6.14838065e-01]\n",
            " [4.11335804e-01 4.47489299e-01 7.22608336e-01 6.40392717e-01\n",
            "  7.14266823e-01 1.57982573e-01 4.66292064e-01 4.69537591e-01\n",
            "  2.22366863e-01 6.04808542e-01]\n",
            " [8.86597545e-01 4.73245306e-01 8.58113173e-01 5.74388616e-01\n",
            "  3.45232052e-01 2.53718758e-01 6.57938390e-01 4.49219167e-01\n",
            "  5.99246790e-01 3.65867733e-01]\n",
            " [6.81841456e-01 5.30425113e-01 9.63461990e-01 7.59919930e-02\n",
            "  1.52309010e-01 2.81343921e-01 9.52567123e-01 3.35690417e-01\n",
            "  2.67652546e-01 5.42359495e-01]\n",
            " [4.07017368e-01 5.23095572e-01 9.98644423e-01 2.27324095e-02\n",
            "  5.11586648e-01 8.50787501e-02 6.06330541e-01 9.72034842e-01\n",
            "  2.89803431e-01 7.11784649e-02]\n",
            " [7.01643415e-01 4.10629327e-01 3.20891884e-01 3.60316687e-01\n",
            "  6.88744497e-01 4.47970204e-01 9.17123619e-01 3.47122869e-01\n",
            "  6.16909746e-02 7.55464797e-01]\n",
            " [5.71587555e-01 5.69462344e-04 8.11983617e-01 9.86250241e-01\n",
            "  9.13900802e-01 7.31115186e-01 3.62088520e-01 4.23883841e-01\n",
            "  2.68225211e-01 8.25470989e-01]\n",
            " [1.02405884e-01 1.36348087e-01 1.08115003e-01 3.41675795e-02\n",
            "  8.80959005e-01 6.97903038e-01 1.62034212e-01 9.58536204e-01\n",
            "  5.32271003e-01 6.27189704e-01]\n",
            " [2.48948277e-02 1.73142328e-01 1.27285848e-01 7.40509962e-01\n",
            "  6.72013797e-01 5.28878160e-02 5.05123377e-02 6.57566228e-01\n",
            "  1.48450910e-01 7.80686760e-01]\n",
            " [4.48519347e-02 4.33076835e-01 6.86260391e-01 3.22311958e-01\n",
            "  5.41512476e-01 5.89470279e-01 2.12739543e-01 7.39811684e-01\n",
            "  3.19500831e-01 4.01279400e-01]\n",
            " [7.21086069e-01 9.16193390e-01 5.91838600e-01 1.94028164e-01\n",
            "  5.07082374e-01 1.11644374e-02 2.29045396e-01 8.70278348e-03\n",
            "  9.63041379e-01 3.24434272e-01]]\n",
            "\n",
            "[0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            " 0.57229226 0.11864827 0.49292349 0.54668355]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "X = np.random.random((32, 10))\n",
        "y = np.random.random((10,))\n",
        "\n",
        "print(X)\n",
        "print()\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Y1SfL0-tbUrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c516f7-420b-4d72-d117-0966e1b6b3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]]\n"
          ]
        }
      ],
      "source": [
        "y = np.expand_dims(y, axis=0)\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "U7uxwZTwbUrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edff29e2-e3b4-4f2f-8014-a102a3b28987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]\n",
            " [0.5030925  0.27140724 0.39985627 0.4030447  0.38861672 0.11786602\n",
            "  0.57229226 0.11864827 0.49292349 0.54668355]]\n"
          ]
        }
      ],
      "source": [
        "Y = np.concatenate([y] * 32, axis=0)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can do *broadcasting* through `concatenate()` function from numpy.\n",
        "- `concatenate()`\n",
        "  - [Microsoft/concatenate](https://support.microsoft.com/en-us/office/concatenate-function-8f8ae884-2ca8-4f7a-b093-75d702bea31d)"
      ],
      "metadata": {
        "id": "DjVB9s0pR89D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tnCK-gj_bUrq"
      },
      "outputs": [],
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2fwjiWNWbUrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d6c486-93b9-45b5-8f37-6637e5ba63a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.80221403 0.61487208 0.73795186 ... 0.57710669 0.03963189\n",
            "    0.01564116]\n",
            "   [0.02476486 0.09361228 0.19893332 ... 0.35571133 0.18984202\n",
            "    0.66996489]\n",
            "   [0.07865988 0.77419826 0.29595243 ... 0.01400519 0.38605772\n",
            "    0.89350121]\n",
            "   ...\n",
            "   [0.33828795 0.99921693 0.25327949 ... 0.22898923 0.87252433\n",
            "    0.787943  ]\n",
            "   [0.60108675 0.66313054 0.63827013 ... 0.52344055 0.73079714\n",
            "    0.37174457]\n",
            "   [0.9552493  0.48976663 0.801862   ... 0.2300665  0.60261393\n",
            "    0.15234723]]\n",
            "\n",
            "  [[0.74561053 0.34540709 0.89535709 ... 0.59731336 0.30356531\n",
            "    0.32110394]\n",
            "   [0.91503022 0.50658155 0.63086103 ... 0.51620998 0.24364004\n",
            "    0.28628969]\n",
            "   [0.36628345 0.75449488 0.46572564 ... 0.02342335 0.84642613\n",
            "    0.87380293]\n",
            "   ...\n",
            "   [0.47389859 0.29782457 0.66667368 ... 0.24155766 0.53941926\n",
            "    0.88672797]\n",
            "   [0.41054492 0.08067127 0.18634833 ... 0.80916472 0.71589038\n",
            "    0.62097937]\n",
            "   [0.50787293 0.20968489 0.71180111 ... 0.68711254 0.16521926\n",
            "    0.75856396]]\n",
            "\n",
            "  [[0.86293787 0.04342155 0.66829702 ... 0.39098231 0.30916302\n",
            "    0.39153889]\n",
            "   [0.24667418 0.98945713 0.07148385 ... 0.80793747 0.70216114\n",
            "    0.46083917]\n",
            "   [0.66577622 0.18069448 0.47715754 ... 0.99445128 0.7359354\n",
            "    0.80467389]\n",
            "   ...\n",
            "   [0.07439583 0.7200179  0.47204365 ... 0.98410652 0.85389478\n",
            "    0.39577836]\n",
            "   [0.94127867 0.53408958 0.13598188 ... 0.26857886 0.74237083\n",
            "    0.05859104]\n",
            "   [0.67598417 0.17189804 0.26593003 ... 0.00610143 0.13783739\n",
            "    0.13165344]]]\n",
            "\n",
            "\n",
            " [[[0.46148858 0.06577132 0.77291554 ... 0.41833996 0.76709972\n",
            "    0.42317274]\n",
            "   [0.16552085 0.63240073 0.25642352 ... 0.08309979 0.25189242\n",
            "    0.68894135]\n",
            "   [0.99320444 0.66502368 0.43679492 ... 0.7739938  0.24041789\n",
            "    0.5919323 ]\n",
            "   ...\n",
            "   [0.69592424 0.262301   0.32178979 ... 0.704769   0.66648454\n",
            "    0.6484755 ]\n",
            "   [0.62240919 0.20825866 0.80064176 ... 0.06958341 0.41665937\n",
            "    0.35818598]\n",
            "   [0.63456011 0.67888214 0.27587144 ... 0.9613372  0.00493587\n",
            "    0.57811731]]\n",
            "\n",
            "  [[0.7843697  0.14185477 0.90572763 ... 0.21107608 0.16809719\n",
            "    0.3832612 ]\n",
            "   [0.64800277 0.15187372 0.53327349 ... 0.02665251 0.95181396\n",
            "    0.95776927]\n",
            "   [0.93105078 0.69788006 0.52420094 ... 0.03755452 0.12012618\n",
            "    0.07204515]\n",
            "   ...\n",
            "   [0.80560433 0.79656857 0.3514307  ... 0.78165856 0.64172268\n",
            "    0.80622667]\n",
            "   [0.88135339 0.15886947 0.39413214 ... 0.27501586 0.27358038\n",
            "    0.54357515]\n",
            "   [0.34985578 0.62907286 0.88359236 ... 0.25158796 0.86218967\n",
            "    0.59028156]]\n",
            "\n",
            "  [[0.59820771 0.34470624 0.5407401  ... 0.65545748 0.91114077\n",
            "    0.32296937]\n",
            "   [0.30779481 0.68873377 0.25787257 ... 0.3409124  0.78611907\n",
            "    0.95779947]\n",
            "   [0.5439864  0.44924379 0.0707733  ... 0.15234486 0.11145267\n",
            "    0.57308843]\n",
            "   ...\n",
            "   [0.51593908 0.71580425 0.98617124 ... 0.23481581 0.92437666\n",
            "    0.02496581]\n",
            "   [0.09220398 0.01251331 0.6324247  ... 0.24976255 0.20135163\n",
            "    0.05704778]\n",
            "   [0.08663039 0.17837364 0.59796093 ... 0.87347359 0.27290341\n",
            "    0.47448227]]]\n",
            "\n",
            "\n",
            " [[[0.07448574 0.89164055 0.07631405 ... 0.48141454 0.85679125\n",
            "    0.82464687]\n",
            "   [0.57230481 0.75912519 0.42808151 ... 0.43615327 0.63448411\n",
            "    0.38658791]\n",
            "   [0.96046137 0.55873027 0.76060298 ... 0.63823984 0.20098534\n",
            "    0.53583116]\n",
            "   ...\n",
            "   [0.23649828 0.72951046 0.18286736 ... 0.42555087 0.11033584\n",
            "    0.32718282]\n",
            "   [0.18078205 0.78254874 0.25904305 ... 0.01152347 0.3820312\n",
            "    0.94058295]\n",
            "   [0.4425966  0.15851368 0.26548495 ... 0.98028228 0.9872389\n",
            "    0.0579182 ]]\n",
            "\n",
            "  [[0.38502423 0.29053488 0.31623422 ... 0.9855308  0.8736694\n",
            "    0.07567972]\n",
            "   [0.77500238 0.77674769 0.60383483 ... 0.59845861 0.90143554\n",
            "    0.96514622]\n",
            "   [0.15104625 0.08952862 0.8871101  ... 0.7381068  0.22079874\n",
            "    0.93340552]\n",
            "   ...\n",
            "   [0.03761402 0.65825681 0.26765053 ... 0.18479332 0.61286469\n",
            "    0.95743769]\n",
            "   [0.69743059 0.61940805 0.62049039 ... 0.16923631 0.32544154\n",
            "    0.07570203]\n",
            "   [0.59410819 0.95335196 0.81868943 ... 0.60838979 0.71378077\n",
            "    0.40180476]]\n",
            "\n",
            "  [[0.45506444 0.59874567 0.8003583  ... 0.87445286 0.99779589\n",
            "    0.62788201]\n",
            "   [0.12680427 0.12832341 0.14522796 ... 0.67360511 0.53413103\n",
            "    0.14921677]\n",
            "   [0.82313041 0.22293731 0.83243434 ... 0.79467529 0.21996834\n",
            "    0.64010895]\n",
            "   ...\n",
            "   [0.06072354 0.22523637 0.49838907 ... 0.32723669 0.63939757\n",
            "    0.97773586]\n",
            "   [0.69522851 0.73277366 0.75683184 ... 0.01588395 0.01411035\n",
            "    0.25401171]\n",
            "   [0.32757128 0.59726686 0.85449896 ... 0.24012845 0.41333392\n",
            "    0.32060759]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.14900655 0.14085745 0.4626624  ... 0.23476338 0.504916\n",
            "    0.89140786]\n",
            "   [0.58974655 0.4506091  0.86399119 ... 0.7952568  0.97533555\n",
            "    0.90395207]\n",
            "   [0.37293749 0.7635633  0.86228267 ... 0.18921082 0.157988\n",
            "    0.95839416]\n",
            "   ...\n",
            "   [0.97412909 0.0424871  0.46600607 ... 0.81083239 0.90118359\n",
            "    0.06987603]\n",
            "   [0.21856566 0.35397327 0.91180594 ... 0.86570299 0.9247425\n",
            "    0.15615737]\n",
            "   [0.07077737 0.89274129 0.36166224 ... 0.19778039 0.37614671\n",
            "    0.89562876]]\n",
            "\n",
            "  [[0.49461979 0.92459067 0.00982703 ... 0.04212022 0.35804327\n",
            "    0.83049134]\n",
            "   [0.59195775 0.2163335  0.3298208  ... 0.80661564 0.3997493\n",
            "    0.56928073]\n",
            "   [0.70376565 0.34760518 0.38788573 ... 0.35640596 0.0924846\n",
            "    0.2512577 ]\n",
            "   ...\n",
            "   [0.72435397 0.97654871 0.15198324 ... 0.18350017 0.79063315\n",
            "    0.39453245]\n",
            "   [0.84336738 0.99266939 0.25045888 ... 0.5641775  0.61242386\n",
            "    0.67305248]\n",
            "   [0.25842275 0.16725677 0.67162106 ... 0.66393744 0.9569856\n",
            "    0.29838741]]\n",
            "\n",
            "  [[0.98889983 0.87430639 0.28312165 ... 0.4484183  0.10868499\n",
            "    0.97732931]\n",
            "   [0.74854087 0.47962874 0.44997535 ... 0.50826369 0.74043558\n",
            "    0.89277503]\n",
            "   [0.48411559 0.7832211  0.88183236 ... 0.872251   0.76287167\n",
            "    0.39163152]\n",
            "   ...\n",
            "   [0.54269838 0.38090756 0.22652073 ... 0.21289591 0.86993234\n",
            "    0.95124607]\n",
            "   [0.46288289 0.01975846 0.60086667 ... 0.13205633 0.01564743\n",
            "    0.66621842]\n",
            "   [0.29986723 0.33353693 0.8888917  ... 0.3556774  0.69905846\n",
            "    0.5041961 ]]]\n",
            "\n",
            "\n",
            " [[[0.21490378 0.07415878 0.52577686 ... 0.94158925 0.16508193\n",
            "    0.45272581]\n",
            "   [0.67437763 0.11989321 0.86738296 ... 0.07535148 0.02858343\n",
            "    0.70150564]\n",
            "   [0.74462982 0.66226573 0.87800238 ... 0.13521097 0.07949384\n",
            "    0.09149008]\n",
            "   ...\n",
            "   [0.68187822 0.71218932 0.74011838 ... 0.61691405 0.49639675\n",
            "    0.65852557]\n",
            "   [0.18507881 0.33442429 0.89024459 ... 0.9115909  0.50598517\n",
            "    0.55185789]\n",
            "   [0.01411594 0.26099642 0.64659505 ... 0.68943953 0.81158924\n",
            "    0.79521131]]\n",
            "\n",
            "  [[0.46391174 0.04874013 0.87646534 ... 0.10654759 0.44604718\n",
            "    0.47047457]\n",
            "   [0.18721947 0.66420045 0.6487088  ... 0.49207464 0.79360945\n",
            "    0.82495129]\n",
            "   [0.72315999 0.8941811  0.20598982 ... 0.87946682 0.33293582\n",
            "    0.90266182]\n",
            "   ...\n",
            "   [0.00158406 0.02476175 0.98885899 ... 0.65406174 0.24466709\n",
            "    0.18281133]\n",
            "   [0.91650876 0.75666247 0.59702318 ... 0.59836103 0.51629299\n",
            "    0.04693703]\n",
            "   [0.70504035 0.54360006 0.8510074  ... 0.23519651 0.63516881\n",
            "    0.95721376]]\n",
            "\n",
            "  [[0.18111839 0.95788695 0.32795295 ... 0.3957743  0.42886492\n",
            "    0.76002021]\n",
            "   [0.49179749 0.03592528 0.33861742 ... 0.46053131 0.34058589\n",
            "    0.17233676]\n",
            "   [0.90295563 0.94846089 0.11945475 ... 0.97903533 0.7309632\n",
            "    0.34121999]\n",
            "   ...\n",
            "   [0.26030995 0.80838756 0.3784615  ... 0.42826162 0.98639411\n",
            "    0.67855055]\n",
            "   [0.66994797 0.34073984 0.35299874 ... 0.49154245 0.99789975\n",
            "    0.41503651]\n",
            "   [0.47618906 0.65863715 0.50853326 ... 0.23061258 0.01619014\n",
            "    0.96890608]]]\n",
            "\n",
            "\n",
            " [[[0.62937435 0.321218   0.92328072 ... 0.87295521 0.08062419\n",
            "    0.30491996]\n",
            "   [0.74916014 0.08042227 0.9851243  ... 0.36086749 0.09836777\n",
            "    0.53272102]\n",
            "   [0.21737336 0.56706611 0.34997054 ... 0.44448315 0.46943287\n",
            "    0.96116958]\n",
            "   ...\n",
            "   [0.1708459  0.01465128 0.69553096 ... 0.25939968 0.83677847\n",
            "    0.5299478 ]\n",
            "   [0.15825924 0.43176772 0.04695572 ... 0.94175245 0.92712028\n",
            "    0.13297771]\n",
            "   [0.9167705  0.69338082 0.61392391 ... 0.17125889 0.01662226\n",
            "    0.3354451 ]]\n",
            "\n",
            "  [[0.24704535 0.78643483 0.75752434 ... 0.57454089 0.98941321\n",
            "    0.72859828]\n",
            "   [0.28228211 0.14798346 0.88178416 ... 0.04419554 0.47734239\n",
            "    0.64744846]\n",
            "   [0.4326969  0.98024355 0.67004482 ... 0.84606482 0.16922151\n",
            "    0.51508787]\n",
            "   ...\n",
            "   [0.70272394 0.05556195 0.61772329 ... 0.80884177 0.44043553\n",
            "    0.76136408]\n",
            "   [0.19307228 0.04954246 0.89383051 ... 0.71982911 0.91623261\n",
            "    0.19771789]\n",
            "   [0.50520778 0.64865502 0.31479546 ... 0.96487929 0.905638\n",
            "    0.91169294]]\n",
            "\n",
            "  [[0.23207897 0.78530881 0.24685626 ... 0.97429465 0.37577219\n",
            "    0.16165638]\n",
            "   [0.87767512 0.23837852 0.83992316 ... 0.74222193 0.88763542\n",
            "    0.76915244]\n",
            "   [0.42868773 0.91826025 0.10965591 ... 0.29252164 0.90148297\n",
            "    0.52262844]\n",
            "   ...\n",
            "   [0.1047536  0.20055983 0.86462947 ... 0.31089817 0.90088906\n",
            "    0.5535964 ]\n",
            "   [0.94786001 0.31369095 0.09641637 ... 0.87901559 0.41202912\n",
            "    0.32274213]\n",
            "   [0.87639643 0.06578873 0.70897452 ... 0.278134   0.91683866\n",
            "    0.24635122]]]] (64, 3, 32, 10)\n",
            "---\n",
            "[[0.51912318 0.25057506 0.56198243 0.91915677 0.13674267 0.2730519\n",
            "  0.50002051 0.40536783 0.43785408 0.01794662]\n",
            " [0.74149376 0.26530064 0.26445657 0.04145907 0.96689272 0.11961595\n",
            "  0.58189488 0.20592884 0.18645535 0.08175366]\n",
            " [0.23869429 0.42589966 0.7719359  0.92295535 0.23123081 0.60265639\n",
            "  0.32257567 0.55077354 0.71307902 0.04725533]\n",
            " [0.65086194 0.72269819 0.87150174 0.45400446 0.94015386 0.81559424\n",
            "  0.21636559 0.43118382 0.67421411 0.52970163]\n",
            " [0.53072663 0.0842854  0.58360288 0.62616651 0.03470736 0.39904937\n",
            "  0.87080052 0.50443792 0.38738666 0.50338413]\n",
            " [0.64922069 0.27244098 0.54556374 0.9982186  0.01661485 0.58738648\n",
            "  0.03160125 0.81005825 0.15234178 0.35552573]\n",
            " [0.23509745 0.53090867 0.02213456 0.49852864 0.37409016 0.30246934\n",
            "  0.88825011 0.58178429 0.14514745 0.69394922]\n",
            " [0.25765154 0.01281689 0.56306204 0.46616531 0.4629555  0.16675915\n",
            "  0.49546296 0.92965026 0.71968642 0.94953468]\n",
            " [0.67047177 0.84530805 0.59919875 0.10110205 0.24597843 0.58161449\n",
            "  0.13390451 0.62252591 0.38970941 0.28739604]\n",
            " [0.4021299  0.01965895 0.22743939 0.56316662 0.32721667 0.95139991\n",
            "  0.16237734 0.5759451  0.01058132 0.28214013]\n",
            " [0.11589077 0.86172255 0.70664368 0.94141754 0.65323462 0.27370596\n",
            "  0.39308249 0.30319809 0.205924   0.02023933]\n",
            " [0.80957644 0.10057885 0.86624466 0.8508283  0.82145519 0.93050914\n",
            "  0.03520791 0.30337818 0.69517742 0.07578021]\n",
            " [0.00900763 0.08491153 0.19057855 0.26201467 0.1649543  0.11106598\n",
            "  0.60511854 0.71953733 0.73493898 0.56496559]\n",
            " [0.11989489 0.93987582 0.80726285 0.14074067 0.04141913 0.98446449\n",
            "  0.71203795 0.90764694 0.62133011 0.20982237]\n",
            " [0.04919929 0.84455993 0.7797834  0.79662564 0.13471281 0.68946531\n",
            "  0.90283939 0.98066376 0.48409023 0.71206993]\n",
            " [0.56247064 0.5116354  0.03116274 0.08742648 0.1552917  0.83550452\n",
            "  0.7527643  0.49966458 0.46446089 0.43103905]\n",
            " [0.09763894 0.7620077  0.31678982 0.99561904 0.85159101 0.00459172\n",
            "  0.74156317 0.6911793  0.3148273  0.51298334]\n",
            " [0.15633485 0.17315535 0.51475128 0.3524489  0.6473218  0.21209832\n",
            "  0.53672917 0.04683353 0.60442084 0.62657768]\n",
            " [0.85691798 0.16107506 0.71037042 0.97082252 0.14968633 0.11598757\n",
            "  0.88166943 0.8462998  0.18712018 0.22453449]\n",
            " [0.653431   0.91527851 0.7687664  0.08796874 0.97804407 0.70290611\n",
            "  0.34435919 0.37845049 0.59445158 0.63494791]\n",
            " [0.47868454 0.52680166 0.21056963 0.78648333 0.72154442 0.38828681\n",
            "  0.66419473 0.79012604 0.39076034 0.9649069 ]\n",
            " [0.79041404 0.07922646 0.53648582 0.80712893 0.45903018 0.24562508\n",
            "  0.00967721 0.58522354 0.40677535 0.4004392 ]\n",
            " [0.81046574 0.13972305 0.58637766 0.37227171 0.45732858 0.87390887\n",
            "  0.28329562 0.5713825  0.29022188 0.15275067]\n",
            " [0.26530614 0.39067228 0.63575974 0.19230987 0.16559698 0.50691531\n",
            "  0.28496567 0.63136376 0.68246377 0.06736332]\n",
            " [0.78495729 0.64581635 0.85658084 0.00893727 0.02198347 0.54056803\n",
            "  0.7791459  0.23780725 0.69718359 0.58803639]\n",
            " [0.72576906 0.55901631 0.53822911 0.0148886  0.73321296 0.73740448\n",
            "  0.16855498 0.61010899 0.93949751 0.84784449]\n",
            " [0.66697943 0.63466186 0.90119997 0.77843447 0.77492124 0.80263212\n",
            "  0.3109447  0.57370328 0.02064812 0.59798464]\n",
            " [0.98122916 0.4333967  0.47001099 0.84660934 0.70607184 0.44939186\n",
            "  0.14800739 0.29080897 0.5902615  0.87870268]\n",
            " [0.6536108  0.4718456  0.63081806 0.02826311 0.66728226 0.55110547\n",
            "  0.49119569 0.48564062 0.48264337 0.79099803]\n",
            " [0.29793507 0.15057463 0.20215733 0.66255303 0.81167703 0.7135827\n",
            "  0.91889753 0.1373536  0.11162557 0.85387507]\n",
            " [0.30366698 0.64043565 0.84392001 0.91460251 0.92659243 0.20398732\n",
            "  0.73688844 0.33528712 0.15072613 0.49978019]\n",
            " [0.92866729 0.48156116 0.05333384 0.14435378 0.38610301 0.06256807\n",
            "  0.96590065 0.30198225 0.0651292  0.20418042]] (32, 10)\n",
            "---\n",
            "[[[[0.80221403 0.61487208 0.73795186 ... 0.57710669 0.43785408\n",
            "    0.01794662]\n",
            "   [0.74149376 0.26530064 0.26445657 ... 0.35571133 0.18984202\n",
            "    0.66996489]\n",
            "   [0.23869429 0.77419826 0.7719359  ... 0.55077354 0.71307902\n",
            "    0.89350121]\n",
            "   ...\n",
            "   [0.33828795 0.99921693 0.25327949 ... 0.22898923 0.87252433\n",
            "    0.85387507]\n",
            "   [0.60108675 0.66313054 0.84392001 ... 0.52344055 0.73079714\n",
            "    0.49978019]\n",
            "   [0.9552493  0.48976663 0.801862   ... 0.30198225 0.60261393\n",
            "    0.20418042]]\n",
            "\n",
            "  [[0.74561053 0.34540709 0.89535709 ... 0.59731336 0.43785408\n",
            "    0.32110394]\n",
            "   [0.91503022 0.50658155 0.63086103 ... 0.51620998 0.24364004\n",
            "    0.28628969]\n",
            "   [0.36628345 0.75449488 0.7719359  ... 0.55077354 0.84642613\n",
            "    0.87380293]\n",
            "   ...\n",
            "   [0.47389859 0.29782457 0.66667368 ... 0.24155766 0.53941926\n",
            "    0.88672797]\n",
            "   [0.41054492 0.64043565 0.84392001 ... 0.80916472 0.71589038\n",
            "    0.62097937]\n",
            "   [0.92866729 0.48156116 0.71180111 ... 0.68711254 0.16521926\n",
            "    0.75856396]]\n",
            "\n",
            "  [[0.86293787 0.25057506 0.66829702 ... 0.40536783 0.43785408\n",
            "    0.39153889]\n",
            "   [0.74149376 0.98945713 0.26445657 ... 0.80793747 0.70216114\n",
            "    0.46083917]\n",
            "   [0.66577622 0.42589966 0.7719359  ... 0.99445128 0.7359354\n",
            "    0.80467389]\n",
            "   ...\n",
            "   [0.29793507 0.7200179  0.47204365 ... 0.98410652 0.85389478\n",
            "    0.85387507]\n",
            "   [0.94127867 0.64043565 0.84392001 ... 0.33528712 0.74237083\n",
            "    0.49978019]\n",
            "   [0.92866729 0.48156116 0.26593003 ... 0.30198225 0.13783739\n",
            "    0.20418042]]]\n",
            "\n",
            "\n",
            " [[[0.51912318 0.25057506 0.77291554 ... 0.41833996 0.76709972\n",
            "    0.42317274]\n",
            "   [0.74149376 0.63240073 0.26445657 ... 0.20592884 0.25189242\n",
            "    0.68894135]\n",
            "   [0.99320444 0.66502368 0.7719359  ... 0.7739938  0.71307902\n",
            "    0.5919323 ]\n",
            "   ...\n",
            "   [0.69592424 0.262301   0.32178979 ... 0.704769   0.66648454\n",
            "    0.85387507]\n",
            "   [0.62240919 0.64043565 0.84392001 ... 0.33528712 0.41665937\n",
            "    0.49978019]\n",
            "   [0.92866729 0.67888214 0.27587144 ... 0.9613372  0.0651292\n",
            "    0.57811731]]\n",
            "\n",
            "  [[0.7843697  0.25057506 0.90572763 ... 0.40536783 0.43785408\n",
            "    0.3832612 ]\n",
            "   [0.74149376 0.26530064 0.53327349 ... 0.20592884 0.95181396\n",
            "    0.95776927]\n",
            "   [0.93105078 0.69788006 0.7719359  ... 0.55077354 0.71307902\n",
            "    0.07204515]\n",
            "   ...\n",
            "   [0.80560433 0.79656857 0.3514307  ... 0.78165856 0.64172268\n",
            "    0.85387507]\n",
            "   [0.88135339 0.64043565 0.84392001 ... 0.33528712 0.27358038\n",
            "    0.54357515]\n",
            "   [0.92866729 0.62907286 0.88359236 ... 0.30198225 0.86218967\n",
            "    0.59028156]]\n",
            "\n",
            "  [[0.59820771 0.34470624 0.56198243 ... 0.65545748 0.91114077\n",
            "    0.32296937]\n",
            "   [0.74149376 0.68873377 0.26445657 ... 0.3409124  0.78611907\n",
            "    0.95779947]\n",
            "   [0.5439864  0.44924379 0.7719359  ... 0.55077354 0.71307902\n",
            "    0.57308843]\n",
            "   ...\n",
            "   [0.51593908 0.71580425 0.98617124 ... 0.23481581 0.92437666\n",
            "    0.85387507]\n",
            "   [0.30366698 0.64043565 0.84392001 ... 0.33528712 0.20135163\n",
            "    0.49978019]\n",
            "   [0.92866729 0.48156116 0.59796093 ... 0.87347359 0.27290341\n",
            "    0.47448227]]]\n",
            "\n",
            "\n",
            " [[[0.51912318 0.89164055 0.56198243 ... 0.48141454 0.85679125\n",
            "    0.82464687]\n",
            "   [0.74149376 0.75912519 0.42808151 ... 0.43615327 0.63448411\n",
            "    0.38658791]\n",
            "   [0.96046137 0.55873027 0.7719359  ... 0.63823984 0.71307902\n",
            "    0.53583116]\n",
            "   ...\n",
            "   [0.29793507 0.72951046 0.20215733 ... 0.42555087 0.11162557\n",
            "    0.85387507]\n",
            "   [0.30366698 0.78254874 0.84392001 ... 0.33528712 0.3820312\n",
            "    0.94058295]\n",
            "   [0.92866729 0.48156116 0.26548495 ... 0.98028228 0.9872389\n",
            "    0.20418042]]\n",
            "\n",
            "  [[0.51912318 0.29053488 0.56198243 ... 0.9855308  0.8736694\n",
            "    0.07567972]\n",
            "   [0.77500238 0.77674769 0.60383483 ... 0.59845861 0.90143554\n",
            "    0.96514622]\n",
            "   [0.23869429 0.42589966 0.8871101  ... 0.7381068  0.71307902\n",
            "    0.93340552]\n",
            "   ...\n",
            "   [0.29793507 0.65825681 0.26765053 ... 0.18479332 0.61286469\n",
            "    0.95743769]\n",
            "   [0.69743059 0.64043565 0.84392001 ... 0.33528712 0.32544154\n",
            "    0.49978019]\n",
            "   [0.92866729 0.95335196 0.81868943 ... 0.60838979 0.71378077\n",
            "    0.40180476]]\n",
            "\n",
            "  [[0.51912318 0.59874567 0.8003583  ... 0.87445286 0.99779589\n",
            "    0.62788201]\n",
            "   [0.74149376 0.26530064 0.26445657 ... 0.67360511 0.53413103\n",
            "    0.14921677]\n",
            "   [0.82313041 0.42589966 0.83243434 ... 0.79467529 0.71307902\n",
            "    0.64010895]\n",
            "   ...\n",
            "   [0.29793507 0.22523637 0.49838907 ... 0.32723669 0.63939757\n",
            "    0.97773586]\n",
            "   [0.69522851 0.73277366 0.84392001 ... 0.33528712 0.15072613\n",
            "    0.49978019]\n",
            "   [0.92866729 0.59726686 0.85449896 ... 0.30198225 0.41333392\n",
            "    0.32060759]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.51912318 0.25057506 0.56198243 ... 0.40536783 0.504916\n",
            "    0.89140786]\n",
            "   [0.74149376 0.4506091  0.86399119 ... 0.7952568  0.97533555\n",
            "    0.90395207]\n",
            "   [0.37293749 0.7635633  0.86228267 ... 0.55077354 0.71307902\n",
            "    0.95839416]\n",
            "   ...\n",
            "   [0.97412909 0.15057463 0.46600607 ... 0.81083239 0.90118359\n",
            "    0.85387507]\n",
            "   [0.30366698 0.64043565 0.91180594 ... 0.86570299 0.9247425\n",
            "    0.49978019]\n",
            "   [0.92866729 0.89274129 0.36166224 ... 0.30198225 0.37614671\n",
            "    0.89562876]]\n",
            "\n",
            "  [[0.51912318 0.92459067 0.56198243 ... 0.40536783 0.43785408\n",
            "    0.83049134]\n",
            "   [0.74149376 0.26530064 0.3298208  ... 0.80661564 0.3997493\n",
            "    0.56928073]\n",
            "   [0.70376565 0.42589966 0.7719359  ... 0.55077354 0.71307902\n",
            "    0.2512577 ]\n",
            "   ...\n",
            "   [0.72435397 0.97654871 0.20215733 ... 0.18350017 0.79063315\n",
            "    0.85387507]\n",
            "   [0.84336738 0.99266939 0.84392001 ... 0.5641775  0.61242386\n",
            "    0.67305248]\n",
            "   [0.92866729 0.48156116 0.67162106 ... 0.66393744 0.9569856\n",
            "    0.29838741]]\n",
            "\n",
            "  [[0.98889983 0.87430639 0.56198243 ... 0.4484183  0.43785408\n",
            "    0.97732931]\n",
            "   [0.74854087 0.47962874 0.44997535 ... 0.50826369 0.74043558\n",
            "    0.89277503]\n",
            "   [0.48411559 0.7832211  0.88183236 ... 0.872251   0.76287167\n",
            "    0.39163152]\n",
            "   ...\n",
            "   [0.54269838 0.38090756 0.22652073 ... 0.21289591 0.86993234\n",
            "    0.95124607]\n",
            "   [0.46288289 0.64043565 0.84392001 ... 0.33528712 0.15072613\n",
            "    0.66621842]\n",
            "   [0.92866729 0.48156116 0.8888917  ... 0.3556774  0.69905846\n",
            "    0.5041961 ]]]\n",
            "\n",
            "\n",
            " [[[0.51912318 0.25057506 0.56198243 ... 0.94158925 0.43785408\n",
            "    0.45272581]\n",
            "   [0.74149376 0.26530064 0.86738296 ... 0.20592884 0.18645535\n",
            "    0.70150564]\n",
            "   [0.74462982 0.66226573 0.87800238 ... 0.55077354 0.71307902\n",
            "    0.09149008]\n",
            "   ...\n",
            "   [0.68187822 0.71218932 0.74011838 ... 0.61691405 0.49639675\n",
            "    0.85387507]\n",
            "   [0.30366698 0.64043565 0.89024459 ... 0.9115909  0.50598517\n",
            "    0.55185789]\n",
            "   [0.92866729 0.48156116 0.64659505 ... 0.68943953 0.81158924\n",
            "    0.79521131]]\n",
            "\n",
            "  [[0.51912318 0.25057506 0.87646534 ... 0.40536783 0.44604718\n",
            "    0.47047457]\n",
            "   [0.74149376 0.66420045 0.6487088  ... 0.49207464 0.79360945\n",
            "    0.82495129]\n",
            "   [0.72315999 0.8941811  0.7719359  ... 0.87946682 0.71307902\n",
            "    0.90266182]\n",
            "   ...\n",
            "   [0.29793507 0.15057463 0.98885899 ... 0.65406174 0.24466709\n",
            "    0.85387507]\n",
            "   [0.91650876 0.75666247 0.84392001 ... 0.59836103 0.51629299\n",
            "    0.49978019]\n",
            "   [0.92866729 0.54360006 0.8510074  ... 0.30198225 0.63516881\n",
            "    0.95721376]]\n",
            "\n",
            "  [[0.51912318 0.95788695 0.56198243 ... 0.40536783 0.43785408\n",
            "    0.76002021]\n",
            "   [0.74149376 0.26530064 0.33861742 ... 0.46053131 0.34058589\n",
            "    0.17233676]\n",
            "   [0.90295563 0.94846089 0.7719359  ... 0.97903533 0.7309632\n",
            "    0.34121999]\n",
            "   ...\n",
            "   [0.29793507 0.80838756 0.3784615  ... 0.42826162 0.98639411\n",
            "    0.85387507]\n",
            "   [0.66994797 0.64043565 0.84392001 ... 0.49154245 0.99789975\n",
            "    0.49978019]\n",
            "   [0.92866729 0.65863715 0.50853326 ... 0.30198225 0.0651292\n",
            "    0.96890608]]]\n",
            "\n",
            "\n",
            " [[[0.62937435 0.321218   0.92328072 ... 0.87295521 0.43785408\n",
            "    0.30491996]\n",
            "   [0.74916014 0.26530064 0.9851243  ... 0.36086749 0.18645535\n",
            "    0.53272102]\n",
            "   [0.23869429 0.56706611 0.7719359  ... 0.55077354 0.71307902\n",
            "    0.96116958]\n",
            "   ...\n",
            "   [0.29793507 0.15057463 0.69553096 ... 0.25939968 0.83677847\n",
            "    0.85387507]\n",
            "   [0.30366698 0.64043565 0.84392001 ... 0.94175245 0.92712028\n",
            "    0.49978019]\n",
            "   [0.92866729 0.69338082 0.61392391 ... 0.30198225 0.0651292\n",
            "    0.3354451 ]]\n",
            "\n",
            "  [[0.51912318 0.78643483 0.75752434 ... 0.57454089 0.98941321\n",
            "    0.72859828]\n",
            "   [0.74149376 0.26530064 0.88178416 ... 0.20592884 0.47734239\n",
            "    0.64744846]\n",
            "   [0.4326969  0.98024355 0.7719359  ... 0.84606482 0.71307902\n",
            "    0.51508787]\n",
            "   ...\n",
            "   [0.70272394 0.15057463 0.61772329 ... 0.80884177 0.44043553\n",
            "    0.85387507]\n",
            "   [0.30366698 0.64043565 0.89383051 ... 0.71982911 0.91623261\n",
            "    0.49978019]\n",
            "   [0.92866729 0.64865502 0.31479546 ... 0.96487929 0.905638\n",
            "    0.91169294]]\n",
            "\n",
            "  [[0.51912318 0.78530881 0.56198243 ... 0.97429465 0.43785408\n",
            "    0.16165638]\n",
            "   [0.87767512 0.26530064 0.83992316 ... 0.74222193 0.88763542\n",
            "    0.76915244]\n",
            "   [0.42868773 0.91826025 0.7719359  ... 0.55077354 0.90148297\n",
            "    0.52262844]\n",
            "   ...\n",
            "   [0.29793507 0.20055983 0.86462947 ... 0.31089817 0.90088906\n",
            "    0.85387507]\n",
            "   [0.94786001 0.64043565 0.84392001 ... 0.87901559 0.41202912\n",
            "    0.49978019]\n",
            "   [0.92866729 0.48156116 0.70897452 ... 0.30198225 0.91683866\n",
            "    0.24635122]]]] (64, 3, 32, 10)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y)\n",
        "\n",
        "print(x, x.shape)\n",
        "print(\"---\")\n",
        "print(y, y.shape)\n",
        "print(\"---\")\n",
        "print(z, z.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1duzdRabUrr"
      },
      "source": [
        "### Tensor product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HcPGJMO1bUrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42fd24d-296e-4e6d-cf32-ec8c5d981312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.73065033 0.91964771 0.96971328 0.97172379 0.59888056 0.51695777\n",
            " 0.77290958 0.82540091 0.78153117 0.75603973 0.0584741  0.54141253\n",
            " 0.85565624 0.89818104 0.21427427 0.02168523 0.03415776 0.66807976\n",
            " 0.30925108 0.62968349 0.1390433  0.74481278 0.94570022 0.28377735\n",
            " 0.77846476 0.3013087  0.99173784 0.18991541 0.13439826 0.49498063\n",
            " 0.99703711 0.40185382] (32,)\n",
            "---\n",
            "[0.09586274 0.27046269 0.86479389 0.30848032 0.64771699 0.75186968\n",
            " 0.78569267 0.66417934 0.19892496 0.01769401 0.71319662 0.44302583\n",
            " 0.59944653 0.1265315  0.4294404  0.97737047 0.78954223 0.48237145\n",
            " 0.11095207 0.91827231 0.41062169 0.83600375 0.94710636 0.37756436\n",
            " 0.35807267 0.75050081 0.82588097 0.90616136 0.53320494 0.81832339\n",
            " 0.06430993 0.55609544] (32,)\n",
            "---\n",
            "9.484076765795784 ()\n"
          ]
        }
      ],
      "source": [
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "z = np.dot(x, y)\n",
        "\n",
        "print(x, x.shape)\n",
        "print(\"---\")\n",
        "print(y, y.shape)\n",
        "print(\"---\")\n",
        "print(z, z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "CyKRtw5EbUrt"
      },
      "outputs": [],
      "source": [
        "def naive_vector_dot(x, y):\n",
        "    assert len(x.shape) == 1\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0.\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습\n",
        "x = x.copy()\n",
        "y = y.copy()\n",
        "\n",
        "print(x, x.shape)\n",
        "print(\"---\")\n",
        "print(y, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrZ8OIEThM8",
        "outputId": "6b7d2a6e-e9f6-4572-c181-f1196f470dfb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.73065033 0.91964771 0.96971328 0.97172379 0.59888056 0.51695777\n",
            " 0.77290958 0.82540091 0.78153117 0.75603973 0.0584741  0.54141253\n",
            " 0.85565624 0.89818104 0.21427427 0.02168523 0.03415776 0.66807976\n",
            " 0.30925108 0.62968349 0.1390433  0.74481278 0.94570022 0.28377735\n",
            " 0.77846476 0.3013087  0.99173784 0.18991541 0.13439826 0.49498063\n",
            " 0.99703711 0.40185382] (32,)\n",
            "---\n",
            "[0.09586274 0.27046269 0.86479389 0.30848032 0.64771699 0.75186968\n",
            " 0.78569267 0.66417934 0.19892496 0.01769401 0.71319662 0.44302583\n",
            " 0.59944653 0.1265315  0.4294404  0.97737047 0.78954223 0.48237145\n",
            " 0.11095207 0.91827231 0.41062169 0.83600375 0.94710636 0.37756436\n",
            " 0.35807267 0.75050081 0.82588097 0.90616136 0.53320494 0.81832339\n",
            " 0.06430993 0.55609544] (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습\n",
        "z = naive_vector_dot(x, y)\n",
        "print(z, z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzyqXyh0UQza",
        "outputId": "b43d0707-0718-4cbb-c14d-0b0035bc1540"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.484076765795784 ()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `np.dot()` vs naive_vector_dot\n",
        "  - each result is same\n",
        "  -"
      ],
      "metadata": {
        "id": "7Dl6tM-OUqUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "WegyD45SbUru"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            z[i] += x[i, j] * y[j]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습"
      ],
      "metadata": {
        "id": "5x4B0b2OV2Ag"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yI6EZcXlbUru"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_dot(x, y):\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        z[i] = naive_vector_dot(x[i, :], y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습"
      ],
      "metadata": {
        "id": "ma6dfI4KV37y"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YWnkHiNZbUrw"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 2\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros((x.shape[0], y.shape[1]))\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(y.shape[1]):\n",
        "            row_x = x[i, :]\n",
        "            column_y = y[:, j]\n",
        "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습"
      ],
      "metadata": {
        "id": "qqMaKgKkV5o4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqSSihlIbUry"
      },
      "source": [
        "### Tensor reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "oiCDMOCwbUry"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "rGVHhzYfbUrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc69539-d849-4bdf-db1c-4953239818c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "x = np.array([[0., 1.],\n",
        "             [2., 3.],\n",
        "             [4., 5.]])\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "kC7qTW1EbUrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202ce4e3-f01f-4d15-b147-bd56a217297c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Lme3yK7IbUr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350548ac-bbb2-4fe2-fbfc-190263554f80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKQqwaKtbUr0"
      },
      "source": [
        "### Geometric interpretation of tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpyecqFwbUr0"
      },
      "source": [
        "### A geometric interpretation of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdt0myASbUr2"
      },
      "source": [
        "## The engine of neural networks: gradient-based optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-5WJRLdbUr2"
      },
      "source": [
        "### What's a derivative?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR4mU1hlbUr3"
      },
      "source": [
        "### Derivative of a tensor operation: the gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh_TU0BZbUr3"
      },
      "source": [
        "### Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUrAYOWFbUr4"
      },
      "source": [
        "### Chaining derivatives: The Backpropagation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuGCnv4qbUr4"
      },
      "source": [
        "#### The chain rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjlbTnmQbUr5"
      },
      "source": [
        "#### Automatic differentiation with computation graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHtlhiqfbUr5"
      },
      "source": [
        "#### The gradient tape in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tf.Variable()\n",
        "  - []()\n",
        "- tf.GradientTape()\n",
        "  - []()\n",
        "- tf.zeros()\n",
        "  - []()\n",
        "- tf.matmul()\n",
        "  - []()"
      ],
      "metadata": {
        "id": "ceO1i1e4XZhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "xIrzhH03bUr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b300d4-03b8-4cfd-c62a-89b383bc83f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>\n",
            "---\n",
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "x = tf.Variable(0.)\n",
        "\n",
        "print(x)\n",
        "print(\"---\")\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)\n",
        "\n",
        "print(grad_of_y_wrt_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Ix4lxnsObUr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf14167-a50f-4a69-aea9-921801b73c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[0.21488011, 0.65127957],\n",
            "       [0.01273763, 0.61183715]], dtype=float32)>\n",
            "---\n",
            "tf.Tensor(\n",
            "[[2. 2.]\n",
            " [2. 2.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable(tf.random.uniform((2, 2)))\n",
        "\n",
        "print(x)\n",
        "print(\"---\")\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)\n",
        "\n",
        "print(grad_of_y_wrt_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "iIoARBmBbUr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6289f26e-2596-41de-ff5a-189449c9f81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[0.36046326, 0.8296114 ],\n",
            "       [0.8105717 , 0.1277771 ]], dtype=float32)>\n",
            "\n",
            "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n",
            "\n",
            "tf.Tensor(\n",
            "[[0.22557926 0.917657  ]\n",
            " [0.9243052  0.34951985]], shape=(2, 2), dtype=float32)\n",
            "---\n",
            "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[1.1498845, 1.1498845],\n",
            "       [1.2671769, 1.2671769]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "W = tf.Variable(tf.random.uniform((2, 2)))\n",
        "b = tf.Variable(tf.zeros((2,)))\n",
        "x = tf.random.uniform((2, 2))\n",
        "\n",
        "print(W)\n",
        "print()\n",
        "print(b)\n",
        "print()\n",
        "print(x)\n",
        "print(\"---\")\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
        "\n",
        "print(grad_of_y_wrt_W_and_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uryre4A4bUr8"
      },
      "source": [
        "## Looking back at our first example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "4QY7XT9qbUr9"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ecrY09_WbUr9"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "jPpxk1ydbUr-"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "3iomlCLubUr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239c4def-e9e7-4261-ddfa-a04e5f0b6dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.4346\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.1126\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0712\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0538\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0377\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f5b379e4850>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8JuoVCDbUsA"
      },
      "source": [
        "### Reimplementing our first example from scratch in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5e6r3zTbUsA"
      },
      "source": [
        "#### A simple Dense class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "8sTvJNHQbUsB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sGtIR4NbUsC"
      },
      "source": [
        "#### A simple Sequential class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "X99ieXBzbUsC"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "VPXlhfsibUsC"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exD = NaiveDense(5, 10, activation=tf.nn.relu)\n",
        "print(exD.weights)\n",
        "print()\n",
        "print(exD.weights[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB8yW3-1YTzZ",
        "outputId": "3eec7218-aaf0-4aad-a711-79908b649cd8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'Variable:0' shape=(5, 10) dtype=float32, numpy=\n",
            "array([[0.02457707, 0.03662499, 0.01703426, 0.06114861, 0.02533321,\n",
            "        0.08895641, 0.01799103, 0.01098953, 0.08766816, 0.07509138],\n",
            "       [0.00704755, 0.06814414, 0.08804735, 0.09133516, 0.0374351 ,\n",
            "        0.0583156 , 0.01040373, 0.03645303, 0.02111764, 0.06257349],\n",
            "       [0.0927823 , 0.00882044, 0.0743442 , 0.02913896, 0.00652092,\n",
            "        0.09209911, 0.03643174, 0.00553263, 0.00704561, 0.04177373],\n",
            "       [0.02476537, 0.02485206, 0.04152761, 0.01850078, 0.07890266,\n",
            "        0.0940925 , 0.08955212, 0.0059985 , 0.09760737, 0.09625236],\n",
            "       [0.07462318, 0.07678872, 0.01888301, 0.08918271, 0.06188503,\n",
            "        0.00650706, 0.01256819, 0.00274332, 0.00422099, 0.01277108]],\n",
            "      dtype=float32)>, <tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n",
            "\n",
            "(5, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4\n",
        "print(model.weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13yIxNywY1um",
        "outputId": "a0c4acb8-2e89-4443-df6d-85266cea25e7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'Variable:0' shape=(784, 512) dtype=float32, numpy=\n",
            "array([[0.08364314, 0.08713499, 0.07063613, ..., 0.0058399 , 0.04598987,\n",
            "        0.07312504],\n",
            "       [0.03233337, 0.01516737, 0.03973464, ..., 0.08848939, 0.08456478,\n",
            "        0.05459403],\n",
            "       [0.09437807, 0.0304301 , 0.07019241, ..., 0.09411204, 0.06169954,\n",
            "        0.02592678],\n",
            "       ...,\n",
            "       [0.06976154, 0.09169378, 0.06540666, ..., 0.04197763, 0.09538694,\n",
            "        0.08423664],\n",
            "       [0.02706267, 0.02140726, 0.01123446, ..., 0.07082727, 0.06878871,\n",
            "        0.06382427],\n",
            "       [0.00926861, 0.02624097, 0.04217144, ..., 0.08126532, 0.09742631,\n",
            "        0.05697244]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(512,) dtype=float32, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0.], dtype=float32)>, <tf.Variable 'Variable:0' shape=(512, 10) dtype=float32, numpy=\n",
            "array([[0.02130219, 0.06895056, 0.00519395, ..., 0.04449583, 0.01417264,\n",
            "        0.07807318],\n",
            "       [0.01038369, 0.0865951 , 0.00397575, ..., 0.08285407, 0.08575519,\n",
            "        0.00466946],\n",
            "       [0.06171459, 0.09675419, 0.02150904, ..., 0.00804163, 0.09218302,\n",
            "        0.05937963],\n",
            "       ...,\n",
            "       [0.05671891, 0.0961023 , 0.05443687, ..., 0.08989117, 0.08298784,\n",
            "        0.04714347],\n",
            "       [0.01269969, 0.01696781, 0.05859139, ..., 0.03764709, 0.09672739,\n",
            "        0.00271519],\n",
            "       [0.02129978, 0.02635274, 0.01114553, ..., 0.09772706, 0.05202545,\n",
            "        0.00065199]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By_H07UubUsD"
      },
      "source": [
        "#### A batch generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "cGrN5TEDbUsD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tflrY4b5bUsE"
      },
      "source": [
        "### Running one training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "i3ZlRFFFbUsF"
      },
      "outputs": [],
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "RbjzWZrIbUsF"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "IXcbh0V6bUsG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qna7EWxXbUsG"
      },
      "source": [
        "### The full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "yegJXnlnbUsH"
      },
      "outputs": [],
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "oiUpLYuIbUsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0181579e-0827-451c-b576-50402b28b634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "loss at batch 0: 4.09\n",
            "loss at batch 100: 2.22\n",
            "loss at batch 200: 2.19\n",
            "loss at batch 300: 2.05\n",
            "loss at batch 400: 2.22\n",
            "Epoch 1\n",
            "loss at batch 0: 1.89\n",
            "loss at batch 100: 1.86\n",
            "loss at batch 200: 1.80\n",
            "loss at batch 300: 1.67\n",
            "loss at batch 400: 1.82\n",
            "Epoch 2\n",
            "loss at batch 0: 1.57\n",
            "loss at batch 100: 1.56\n",
            "loss at batch 200: 1.48\n",
            "loss at batch 300: 1.40\n",
            "loss at batch 400: 1.50\n",
            "Epoch 3\n",
            "loss at batch 0: 1.31\n",
            "loss at batch 100: 1.33\n",
            "loss at batch 200: 1.22\n",
            "loss at batch 300: 1.19\n",
            "loss at batch 400: 1.28\n",
            "Epoch 4\n",
            "loss at batch 0: 1.12\n",
            "loss at batch 100: 1.15\n",
            "loss at batch 200: 1.04\n",
            "loss at batch 300: 1.04\n",
            "loss at batch 400: 1.12\n",
            "Epoch 5\n",
            "loss at batch 0: 0.98\n",
            "loss at batch 100: 1.02\n",
            "loss at batch 200: 0.91\n",
            "loss at batch 300: 0.92\n",
            "loss at batch 400: 1.00\n",
            "Epoch 6\n",
            "loss at batch 0: 0.88\n",
            "loss at batch 100: 0.91\n",
            "loss at batch 200: 0.81\n",
            "loss at batch 300: 0.84\n",
            "loss at batch 400: 0.91\n",
            "Epoch 7\n",
            "loss at batch 0: 0.80\n",
            "loss at batch 100: 0.83\n",
            "loss at batch 200: 0.73\n",
            "loss at batch 300: 0.77\n",
            "loss at batch 400: 0.84\n",
            "Epoch 8\n",
            "loss at batch 0: 0.73\n",
            "loss at batch 100: 0.76\n",
            "loss at batch 200: 0.67\n",
            "loss at batch 300: 0.71\n",
            "loss at batch 400: 0.79\n",
            "Epoch 9\n",
            "loss at batch 0: 0.68\n",
            "loss at batch 100: 0.71\n",
            "loss at batch 200: 0.62\n",
            "loss at batch 300: 0.67\n",
            "loss at batch 400: 0.75\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f4tQVJNbUsI"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "0U-sJMMNbUsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7a2442-acf0-41cc-b107-1814756f35ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.81\n"
          ]
        }
      ],
      "source": [
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLcxMZO2bUsJ"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "aRS_VN5jbUqm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}